<!DOCTYPE html><html lang="zh" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>ylifs的博客</title><meta name="author" content="ylifs"><meta name="copyright" content="ylifs"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="普通本科生，研究领域为神经网络、多目标智能优化、生物信息、联邦学习">
<meta property="og:type" content="website">
<meta property="og:title" content="ylifs的博客">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="ylifs的博客">
<meta property="og:description" content="普通本科生，研究领域为神经网络、多目标智能优化、生物信息、联邦学习">
<meta property="og:locale">
<meta property="og:image" content="https://img1.imgtp.com/2023/02/12/mpw2AfRT.jpg">
<meta property="article:author" content="ylifs">
<meta property="article:tag" content="神经网络、多目标智能优化、生物信息、联邦学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img1.imgtp.com/2023/02/12/mpw2AfRT.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/page/2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'ylifs的博客',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-02-22 23:47:38'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://img1.imgtp.com/2023/02/12/mpw2AfRT.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> todolist</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/todolist"><span> url</span></a></li><li><a class="site-page child" href="/fas"><span> icon</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header" style="background-image: url('https://img1.imgtp.com/2023/02/12/qifMpDVt.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">ylifs的博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> todolist</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/todolist"><span> url</span></a></li><li><a class="site-page child" href="/fas"><span> icon</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">ylifs的博客</h1><div id="site_social_icons"><a class="social-icon" href="https://github.com/lftxd1" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ylifs@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/09/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E8%8A%82%E7%AD%96%E7%95%A5OneCycleLR/" title="学习率调节策略OneCycleLR"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e7e9d680e.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="学习率调节策略OneCycleLR"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/09/%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%B0%83%E8%8A%82%E7%AD%96%E7%95%A5OneCycleLR/" title="学习率调节策略OneCycleLR">学习率调节策略OneCycleLR</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-08T16:59:40.000Z" title="Created 2022-12-09 00:59:40">2022-12-09</time></span></div><div class="content">简介
　　论文中作者将神经网络的快速收敛称为"super-convergence"。在Cifar-10上训练56层的残差网络时，发现测试集上的准确率在使用高学习率和相对较少的训练轮次的时候也依然保持较高（如下图所示），这个现象给"super-convergence"提供了可能。
这说明在高学习率的某些情况下的更新并不会破坏网络。

　作者为了达到"super-convergence"的目的，设计出了一种新的学习率scheduler，称为"1cycle"。在讲"1cycle"之前，有必要先介绍一下cyclical
learning rates (CLR)。

　　CLR（如上图所示）不是单调地降低训练过程中的学习率，而是让学习率在设定好地最大值与最小值之间往复变化，文中提出CLR能够work的原因在于两点：　

CLR里面增大学习率的过程可以帮助损失函数值逃离鞍点　
最优的学习率会在设定好的最大值与最小值之间，最优学习率附近的值在整个训练过程中会被一直使用到。\(stepsize\)一般设置为\(number of
samplesbatchsize\)的2-10倍， ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/12/08/EfficientNetV1%E5%92%8CMobileNet/" title="EfficientNetV1和MobileNet"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e5eb70f31.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="EfficientNetV1和MobileNet"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/08/EfficientNetV1%E5%92%8CMobileNet/" title="EfficientNetV1和MobileNet">EfficientNetV1和MobileNet</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-08T03:46:24.000Z" title="Created 2022-12-08 11:46:24">2022-12-08</time></span></div><div class="content">前言
在之前的一些手工设计网络中(AlexNet，VGG，ResNet等等)经常有人问，为什么输入图像分辨率要固定为224，为什么卷积的个数要设置为这个值，为什么网络的深度设为这么深？这些问题你要问设计作者的话，估计回复就四个字——工程经验。而这篇论文主要是用NAS（Neural
Architecture
Search）技术来搜索网络的图像输入分辨率，网络的深度以及通道的宽度三个参数的合理化配置。在之前的一些论文中，基本都是通过改变上述3个参数中的一个来提升网络的性能，而这篇论文就是同时来探索这三个参数的影响。在论文中提到，本文提出的EfficientNet-B7在Imagenet
top-1上达到了当年最高准确率84.3%，与之前准确率最高的GPipe相比，参数数量（Params）仅为其1/8.4，推理速度提升了6.1倍（看上去又快又轻量，但个人实际使用起来发现很吃显存）。下图是EfficientNet与其他网络的对比（注意，参数数量少并不意味推理速度就快）。
## 论文思想
在之前的一些论文中，有的会通过增加网络的width即增加卷积核的个数（增加特征矩阵的channe ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/07/%E9%AA%8C%E8%AF%81%E7%9A%84%E6%97%B6%E5%80%99%E8%AE%B0%E5%BE%97%E5%90%AF%E7%94%A8Eval/" title="验证的时候记得启用Eval!"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e76a84898.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="验证的时候记得启用Eval!"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/07/%E9%AA%8C%E8%AF%81%E7%9A%84%E6%97%B6%E5%80%99%E8%AE%B0%E5%BE%97%E5%90%AF%E7%94%A8Eval/" title="验证的时候记得启用Eval!">验证的时候记得启用Eval!</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-07T02:40:17.000Z" title="Created 2022-12-07 10:40:17">2022-12-07</time></span></div><div class="content">
Model.eval 的作用是禁止批正则化层更新均值和方差。
当数据以个为单位进入，不存在均值，为避免均值和方差更新，因此需要开启。
实际中发现:

测试模型的时候是以Batch为单位测试，因此理论上可以不开启。
在训练的前期不开启有助于实现更高的指标。
准确率到达92以后，如果不关闭，准确率将不会再提升。


结论，请默认开启！
</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/12/07/%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%97%B6%E5%8A%A0%E4%B8%8A%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%90%A7/" title="训练模型时加上图像数据增强吧"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e74d16937.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="训练模型时加上图像数据增强吧"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/07/%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%97%B6%E5%8A%A0%E4%B8%8A%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%90%A7/" title="训练模型时加上图像数据增强吧">训练模型时加上图像数据增强吧</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-06T16:45:44.000Z" title="Created 2022-12-07 00:45:44">2022-12-07</time></span></div><div class="content">介绍
数据增强是防止过拟合最有效的方法，采取有效的数据增强策略可以将数据扩大十倍有余，有效提升模型泛化性，抑制过拟合。
全家福
123456789101112transform_train = transforms.Compose([    transforms.ColorJitter(brightness=0.8, contrast=0.8, saturation=0.8),    transforms.RandomCrop(32, padding=4),  #先四周填充0，在吧图像随机裁剪成32*32    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转    transforms.RandomRotation(degrees=10),    transforms.ToTensor(),    Cutout(n_holes=5, length=4),    transforms.Normalize(mean=CIFAR_MEAN,std=CIFAR_STD), #R,G,B每层的归一化用到的均值和方差   ]) ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/05/%E5%BF%AB%E6%9D%A5%E4%BD%BF%E7%94%A8%E4%BC%98%E5%8C%96%E4%BD%A0%E7%9A%84Pytorch%E7%9A%84%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%90%A7/" title="快来优化你的Pytorch的显存占用吧"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e89fb7622.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="快来优化你的Pytorch的显存占用吧"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/05/%E5%BF%AB%E6%9D%A5%E4%BD%BF%E7%94%A8%E4%BC%98%E5%8C%96%E4%BD%A0%E7%9A%84Pytorch%E7%9A%84%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E5%90%A7/" title="快来优化你的Pytorch的显存占用吧">快来优化你的Pytorch的显存占用吧</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-04T18:43:20.000Z" title="Created 2022-12-05 02:43:20">2022-12-05</time></span></div><div class="content">介绍
本文介绍了使用混合精度训练和验证禁用梯度来优化显存的占用。根据笔者实测，混合精度训练对网络的影响几乎可以忽略不及，但是显存可以降低一半以上。
混合精度训练
1234567891011121314151617181920from torch.cuda.amp import autocastfrom torch.cuda.amp import GradScalerscaler = GradScaler()optimizer = optim.SGD(model.parameters(), lr=0.04, momentum=0.7, weight_decay=5e-4)for epoch in range(0, n_epochs):    train_loss = 0.0    valid_loss = 0.0    model.train()     for data, target in train_loader:        optimizer.zero_grad()        data = data.to(device)        target = target ...</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/12/05/%E6%88%90%E5%8A%9F%E5%AE%9E%E7%8E%B0Pytorch%E5%B9%B6%E8%A1%8C%E8%BF%90%E7%AE%97%EF%BC%81/" title="成功实现Pytorch并行运算！"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e6fbb2fc4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="成功实现Pytorch并行运算！"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/05/%E6%88%90%E5%8A%9F%E5%AE%9E%E7%8E%B0Pytorch%E5%B9%B6%E8%A1%8C%E8%BF%90%E7%AE%97%EF%BC%81/" title="成功实现Pytorch并行运算！">成功实现Pytorch并行运算！</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-04T18:22:38.000Z" title="Created 2022-12-05 02:22:38">2022-12-05</time></span></div><div class="content">介绍
在模型中进程会出现并行运算，比如在下列的\(InceptionV3\)的算子中：

三条支路的计算可以同步运算，如果实现，理论上可以达到3倍加速。
方案说明

torch.multiprocessing as mp
这是Pytorch实现的多进程库，采用的是Fork的方式实现多进程，具体而言就是在Start进程的位置继承前面的变量开启新的进程，很遗憾的是，一般情况下网络是不能共享的，两个进程各训练各的，最终都不返回训练的网络。需要使用另外一个库才能使其返回训练的梯度，和目前需求是不满足的。
Python官方的多进程库无法同时调用Cuda.
最终选用的方案是多线程，由于多个线程无需切换上下文，因此官方的Thread就可以实现并行运算，但是我们不能无限的把进程开下去，因此需要一个线程池进行管理，最终使用一个等待来等待线程的关闭，理论上协程也可以实现。

代码示例
联邦学习
1234567891011121314151617181920212223from concurrent.futures import ThreadPoolExecutorthread_p ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/03/%E5%85%88%E8%BF%9B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" title="先进神经网络结构"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e69be5b4a.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="先进神经网络结构"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/03/%E5%85%88%E8%BF%9B%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" title="先进神经网络结构">先进神经网络结构</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-03T04:24:02.000Z" title="Created 2022-12-03 12:24:02">2022-12-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">Inceptionv3
InceptionV3模型是谷歌Inception系列里面的第三代模型，其模型结构与InceptionV2模型放在了同一篇论文里，其实二者模型结构差距不大，相比于其它神经网络模型，Inception网络最大的特点在于将神经网络层与层之间的卷积运算进行了拓展。
如VGG，AlexNet网络，它就是一直卷积下来的，一层接着一层；
ResNet则是创新性的引入了残差网络的概念，使得靠前若干层的某一层数据输出直接跳过多层引入到后面数据层的输入部分，后面的特征层的内容会有一部分由其前面的某一层线性贡献。
而Inception网络则是采用不同大小的卷积核，使得存在不同大小的感受野，最后实现拼接达到不同尺度特征的融合。
对于InceptionV3而言，其网络中存在着如下的结构。


img




</div></div></div><div class="recent-post-item"><div class="post_cover right"><a href="/2022/12/02/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2/" title="神经网络结构搜索"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e715208b7.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络结构搜索"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/02/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2/" title="神经网络结构搜索">神经网络结构搜索</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-02T09:56:56.000Z" title="Created 2022-12-02 17:56:56">2022-12-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97/">智能计算</a></span></div><div class="content">GreedyNAS
动机与背景与思路
在目前的神经结构搜索领域中，One-Shot
NAS方法由于其搜索开销小被广泛应用，这些方法使用一个权重共享的超网络（Supernet）作为不同网络结构的性能评估器，因此，Supernet的训练对搜索结果的好坏至关重要。准确的评估对于Supernet来说是非常困难的，导致Supernet中结构的表现与其真实表现相关性很差
[1]。
在本篇论文中，我们提出一种贪心超网络来减轻Supernet的评估压力，使得Supernet更加贪心地注重于有潜力的好结构，而不是全体。具体而言，在Supernet训练过程中，我们提出了一种多路径拒绝式采样方法(Multi-path
sampling with rejection)来进行路径滤波 (path
filtering)，使得有潜力的好结构得到训练。
通过这种方法，Supernet的训练从整个搜索空间贪心地缩小到了有潜力的结构组成的空间中，因此训练的效率得到了提升。同时，为了进一步增大有潜力结构的采样概率与提高训练效率，我们基于Exploration
and
Exploitation准则，使用一 ...</div></div></div><div class="recent-post-item"><div class="post_cover left"><a href="/2022/12/02/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="联邦学习"><img class="post_bg" src="https://www.hualigs.cn/image/63e8e73162a4a.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="联邦学习"></a></div><div class="recent-post-info"><a class="article-title" href="/2022/12/02/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" title="联邦学习">联邦学习</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-12-01T17:05:11.000Z" title="Created 2022-12-02 01:05:11">2022-12-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></span></div><div class="content">摘要: 本文介绍了联邦学习的概念与各种算法以及具体实现。

FedAvg算法
联邦学习原始论文中给出的FedAvg的算法框架为：


在这里插入图片描述

参数介绍：\(K\)表示客户端的个数，\(B\) 表示Batch_size，\(E\)表示本地更新的次数，\(\eta\)表示学习率。 \(P_k\)表示该客户端所有的数据。另外一个B表示的是由切分后的数据Batch组成的集合，\(C\)是比例,当\(C==1\)算法变为FedSGD。

从\(n\)个客户端选出随机选出\(m\)个客户端。
\(S_t\)为客户端的随机序列。
\(S_t\)中每个客户端并行进行梯度下降。
上传模型，中心服务器进行平均。
注意，我们发现


image-20221202081253192


全局模型的生成这一步对K个模型都进行了求和，但是实际上只抽样了m个客户端，我认为这种写法还是错误的。参考了书本和很多博客，这一步想要表达的意思就是说，随机选择m个客户端采样，对这m个客户端的梯度更新进行平均以形成全局更新，同时用当前全局模型替换未采样的客户端。\(n_k\) ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://img1.imgtp.com/2023/02/12/mpw2AfRT.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ylifs</div><div class="author-info__description">普通本科生，研究领域为神经网络、多目标智能优化、生物信息、联邦学习</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">19</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lftxd1"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lftxd1" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ylifs@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">原神主题博客站</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/02/22/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%85%A5%E9%97%A8/" title="高等数学入门"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="高等数学入门"/></a><div class="content"><a class="title" href="/2023/02/22/%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%E5%85%A5%E9%97%A8/" title="高等数学入门">高等数学入门</a><time datetime="2023-02-22T14:47:15.000Z" title="Created 2023-02-22 22:47:15">2023-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/22/%E6%A6%82%E7%8E%87%E8%AE%BA%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/" title="概率论零基础入门"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="概率论零基础入门"/></a><div class="content"><a class="title" href="/2023/02/22/%E6%A6%82%E7%8E%87%E8%AE%BA%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/" title="概率论零基础入门">概率论零基础入门</a><time datetime="2023-02-22T14:25:24.000Z" title="Created 2023-02-22 22:25:24">2023-02-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/13/Python%E7%BC%96%E7%A8%8B100%E9%97%AE/" title="百问Python编程"><img src="https://www.hualigs.cn/image/63ea153982f8c.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="百问Python编程"/></a><div class="content"><a class="title" href="/2023/02/13/Python%E7%BC%96%E7%A8%8B100%E9%97%AE/" title="百问Python编程">百问Python编程</a><time datetime="2023-02-13T06:32:55.000Z" title="Created 2023-02-13 14:32:55">2023-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/12/Hexo%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/" title="Hexo配置指南"><img src="https://www.hualigs.cn/image/63e8e5fb168c2.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo配置指南"/></a><div class="content"><a class="title" href="/2023/02/12/Hexo%E9%85%8D%E7%BD%AE%E6%8C%87%E5%8D%97/" title="Hexo配置指南">Hexo配置指南</a><time datetime="2023-02-12T12:59:30.287Z" title="Created 2023-02-12 20:59:30">2023-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/02/09/Jupyter%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="Jupyter使用指南"><img src="https://www.hualigs.cn/image/63e8ea30a8314.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Jupyter使用指南"/></a><div class="content"><a class="title" href="/2023/02/09/Jupyter%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/" title="Jupyter使用指南">Jupyter使用指南</a><time datetime="2023-02-09T14:20:13.000Z" title="Created 2023-02-09 22:20:13">2023-02-09</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%99%E7%A8%8B%E6%8C%87%E5%8D%97/"><span class="card-category-list-name">教程指南</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97/"><span class="card-category-list-name">智能计算</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">算法</span><span class="card-category-list-count">1</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Python/" style="font-size: 1.1em; color: #999">Python</a> <a href="/tags/linux/" style="font-size: 1.1em; color: #999">linux</a> <a href="/tags/python/" style="font-size: 1.5em; color: #99a9bf">python</a> <a href="/tags/pytorch/" style="font-size: 1.1em; color: #999">pytorch</a> <a href="/tags/pytorch%E6%8A%80%E5%B7%A7/" style="font-size: 1.1em; color: #999">pytorch技巧</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/" style="font-size: 1.1em; color: #999">图像处理</a> <a href="/tags/%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96/" style="font-size: 1.1em; color: #999">多目标优化</a> <a href="/tags/%E5%AD%A6%E4%B9%A0%E7%8E%87%E7%AD%96%E7%95%A5/" style="font-size: 1.1em; color: #999">学习率策略</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/" style="font-size: 1.1em; color: #999">数据增强</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.5em; color: #99a9bf">深度学习</a> <a href="/tags/%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6/" style="font-size: 1.1em; color: #999">混合精度</a> <a href="/tags/%E7%82%BC%E4%B8%B9%E7%BB%86%E8%8A%82/" style="font-size: 1.1em; color: #999">炼丹细节</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 1.1em; color: #999">神经网络</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2/" style="font-size: 1.1em; color: #999">神经网络结构搜索</a> <a href="/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 1.1em; color: #999">联邦学习</a> <a href="/tags/%E8%AE%BA%E6%96%87%E6%80%BB%E7%BB%93/" style="font-size: 1.1em; color: #999">论文总结</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">February 2023</span><span class="card-archive-list-count">8</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/12/"><span class="card-archive-list-date">December 2022</span><span class="card-archive-list-count">11</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">19</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-02-22T15:47:38.692Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By ylifs</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>